// Module included in the following assemblies:
//


:_mod-docs-content-type: PROCEDURE
[id="logging-elastic-to-loki-store_{context}"]
= Changing the default log store from Elasticsearch to Loki

This guide describes how to switch the OpenShift Logging storage service from Elasticsearch to LokiStack. It focuses on log forwarding, not data migration. After following these steps, old logs will remain in Elasticsearch (accessible via Kibana), while new logs will go to LokiStack (visible in the OpenShift Console).

.Prerequisites

* Red Hat OpenShift Logging Operator (v5.5.5+)
* OpenShift Elasticsearch Operator (v5.5.5+)
* Red Hat Loki Operator (v5.5.5+)
* Sufficient resources on target nodes to run both Elasticsearch and LokiStack (see LokiStack Deployment Sizing Table in the documentation).

== Installing LokiStack

. **Install the Loki Operator:** Follow the official guide to install the Loki Operator using the OpenShift web console.
.. **Create a Secret for Loki Object Storage:** Create a secret for Loki object storage (e.g., AWS S3). Refer to the documentation for other object storage types.

[source,bash]
----
$ cat << EOF |oc create -f -
apiVersion: v1
kind: Secret
metadata:
  name: logging-loki-s3
  namespace: openshift-logging
data:
  access_key_id: $(echo "PUT_S3_ACCESS_KEY_ID_HERE" | base64 -w0)
  access_key_secret: $(echo "PUT_S3_ACCESS_KEY_SECRET_HERE" | base64 -w0)
  bucketnames: $(echo "s3-bucket-name" | base64 -w0)
  endpoint: $(echo "https://s3.eu-central-1.amazonaws.com" | base64 -w0)
  region: $(echo "eu-central-1" | base64 -w0)
EOF
----


... **Deploy LokiStack Custom Resource (CR):**

[NOTE]
====
Change the `spec.size` if needed.
====

[source,bash]
----
$ cat << EOF |oc create -f -
apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  size: 1x.small
  storage:
    schemas:
    - version: v12
      effectiveDate: '2022-06-01'
    secret:
      name: logging-loki-s3
      type: s3
  storageClassName: gp2
  tenants:
    mode: openshift-logging
EOF
----

== Disconnecting Elasticsearch and Kibana

To keep Elasticsearch and Kibana running while transitioning:

. **Set `ClusterLogging` to Unmanaged:**

[source,bash]
----
oc -n openshift-logging patch clusterlogging/instance -p '{"spec":{"managementState": "Unmanaged"}}' --type=merge
----

.. **Remove Owner References:** Remove `ClusterLogging` owner references from Elasticsearch and Kibana resources:

[source,bash]
----
$ oc -n openshift-logging patch elasticsearch/elasticsearch -p '{"metadata":{"ownerReferences": []}}' --type=merge
----

[source,bash]
----
$ oc -n openshift-logging patch kibana/kibana -p '{"metadata":{"ownerReferences": []}}' --type=merge
----

... **Back Up Elasticsearch and Kibana Resources:** Use `yq` to back up these resources to prevent accidental deletion: link:https://github.com/mikefarah/yq[yq utility]

For Elasticsearch:

[source,bash]// Module included in the following assemblies:
//


:_mod-docs-content-type: PROCEDURE
[id="logging-elastic-to-loki-migration_{context}"]
= Migrating the Default Log Store from Elasticsearch to Loki in OpenShift

This guide describes how to switch the OpenShift Logging storage service from Elasticsearch to LokiStack. It focuses on log forwarding, not data migration. After following these steps, old logs will remain in Elasticsearch (accessible via Kibana), while new logs will go to LokiStack (visible in the OpenShift Console).

.Prerequisites

* Red Hat OpenShift Logging Operator (v5.5.5+)
* OpenShift Elasticsearch Operator (v5.5.5+)
* Red Hat Loki Operator (v5.5.5+)
* Sufficient resources on target nodes to run both Elasticsearch and LokiStack (see LokiStack Deployment Sizing Table in the documentation).

== Installing LokiStack

. **Install the Loki Operator:** Follow the official guide to install the Loki Operator using the OpenShift web console.
.. **Create a Secret for Loki Object Storage:** Create a secret for Loki object storage (e.g., AWS S3). Refer to the documentation for other object storage types.

[source,bash]
----
$ cat << EOF |oc create -f -
apiVersion: v1
kind: Secret
metadata:
  name: logging-loki-s3
  namespace: openshift-logging
data:
  access_key_id: $(echo "PUT_S3_ACCESS_KEY_ID_HERE" | base64 -w0)
  access_key_secret: $(echo "PUT_S3_ACCESS_KEY_SECRET_HERE" | base64 -w0)
  bucketnames: $(echo "s3-bucket-name" | base64 -w0)
  endpoint: $(echo "https://s3.eu-central-1.amazonaws.com" | base64 -w0)
  region: $(echo "eu-central-1" | base64 -w0)
EOF
----


... **Deploy LokiStack Custom Resource (CR):**

[NOTE]
====
Change the `spec.size` if needed.
====

[source,bash]
----
$ cat << EOF |oc create -f -
apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  size: 1x.small
  storage:
    schemas:
    - version: v12
      effectiveDate: '2022-06-01'
    secret:
      name: logging-loki-s3
      type: s3
  storageClassName: gp2
  tenants:
    mode: openshift-logging
EOF
----

== Disconnecting Elasticsearch and Kibana

To keep Elasticsearch and Kibana running while transitioning:

. **Set `ClusterLogging` to Unmanaged:**

[source,bash]
----
oc -n openshift-logging patch clusterlogging/instance -p '{"spec":{"managementState": "Unmanaged"}}' --type=merge
----

.. **Remove Owner References:** Remove `ClusterLogging` owner references from Elasticsearch and Kibana resources:

[source,bash]
----
$ oc -n openshift-logging patch elasticsearch/elasticsearch -p '{"metadata":{"ownerReferences": []}}' --type=merge
----

[source,bash]
----
$ oc -n openshift-logging patch kibana/kibana -p '{"metadata":{"ownerReferences": []}}' --type=merge
----

... **Back Up Elasticsearch and Kibana Resources:** Use `yq` to back up these resources to prevent accidental deletion: link:https://github.com/mikefarah/yq[yq utility]

For Elasticsearch:

[source,bash]
----
$ oc -n openshift-logging get elasticsearch elasticsearch -o yaml \
    | yq 'del(.metadata.resourceVersion) | del(.metadata.uid)'  \
    | yq 'del(.metadata.generation) | del(.metadata.creationTimestamp)'  \
    | yq 'del(.metadata.selfLink) | del(.status)' > /tmp/cr-elasticsearch.yaml
----

For Kibana:

[source,bash]
----
$ oc -n openshift-logging get kibana kibana -o yaml \
    | yq 'del(.metadata.resourceVersion) | del(.metadata.uid)'  \
    | yq 'del(.metadata.generation) | del(.metadata.creationTimestamp)'  \
    | yq 'del(.metadata.selfLink) | del(.status)' > /tmp/cr-kibana.yaml
----

== Switching to LokiStack

. Switch Log Storage to LokiStack
The following manifest will apply several changes to the `ClusterLogging` resource:
* Re-instate the management state to `Managed`.
* Switch the `logStore` spec from `elasticsearch` to `lokistack`, restarting the collector pods to start forwarding logs to `lokistack`.
* Remove the `visualization` spec, prompting the cluster-logging-operator to install the `logging-view-plugin` for observing `lokistack` logs in the OpenShift Console.
* If the collection type is not `fluentd`, replace it with `vector`.

[source,yaml]
----
$ cat << EOF |oc replace -f -
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  managementState: Managed
  logStore:
    type: lokistack
    lokistack:
      name: logging-loki
  collection:
    logs:
      type: fluentd
      fluentd: {}
  visualization:
    type: kibana
    kibana:
      replicas: 1
EOF
----

. Re-instantiate Kibana Resource

In the previous step, removing the `visualization` field prompted the operator to remove the `Kibana` resource. Re-instantiate the `Kibana` resource using the backup created earlier.

[source,bash]
----
$ oc -n openshift-logging apply -f /tmp/cr-kibana.yaml
----

. Enable the Console View Plugin

Enable the console view plugin to view the logs integrated from the OpenShift Console (Observe > Logs).

[source,bash]
----
$ oc patch consoles.operator.openshift.io cluster --type=merge --patch '{ "spec": { "plugins": ["logging-view-plugin"] } }'
----

== Delete the Elasticsearch Stack

Once the retention period for logs stored in Elasticsearch expires and no more logs are visible in Kibana, remove the old stack to release resources.

=== Step 1: Delete Elasticsearch and Kibana Resources

[source,bash]
----
$ oc -n openshift-logging delete kibana/kibana elasticsearch/elasticsearch
----

===

 Step 2: Delete the PVCs Used by Elasticsearch Instances

[source,bash]
----
$ oc delete -n openshift-logging pvc -l logging-cluster=elasticsearch
----
----
$ oc -n openshift-logging get elasticsearch elasticsearch -o yaml \
    | yq 'del(.metadata.resourceVersion) | del(.metadata.uid)'  \
    | yq 'del(.metadata.generation) | del(.metadata.creationTimestamp)'  \
    | yq 'del(.metadata.selfLink) | del(.status)' > /tmp/cr-elasticsearch.yaml
----

For Kibana:

[source,bash]
----
$ oc -n openshift-logging get kibana kibana -o yaml \
    | yq 'del(.metadata.resourceVersion) | del(.metadata.uid)'  \
    | yq 'del(.metadata.generation) | del(.metadata.creationTimestamp)'  \
    | yq 'del(.metadata.selfLink) | del(.status)' > /tmp/cr-kibana.yaml
----

== Switching to LokiStack

. Switch Log Storage to LokiStack
The following manifest will apply several changes to the `ClusterLogging` resource:
* Re-instate the management state to `Managed`.
* Switch the `logStore` spec from `elasticsearch` to `lokistack`, restarting the collector pods to start forwarding logs to `lokistack`.
* Remove the `visualization` spec, prompting the cluster-logging-operator to install the `logging-view-plugin` for observing `lokistack` logs in the OpenShift Console.
* If the collection type is not `fluentd`, replace it with `vector`.

[source,yaml]
----
$ cat << EOF |oc replace -f -
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  managementState: Managed
  logStore:
    type: lokistack
    lokistack:
      name: logging-loki
  collection:
    logs:
      type: fluentd
      fluentd: {}
  visualization:
    type: kibana
    kibana:
      replicas: 1
EOF
----

. Re-instantiate Kibana Resource

In the previous step, removing the `visualization` field prompted the operator to remove the `Kibana` resource. Re-instantiate the `Kibana` resource using the backup created earlier.

[source,bash]
----
$ oc -n openshift-logging apply -f /tmp/cr-kibana.yaml
----

. Enable the Console View Plugin

Enable the console view plugin to view the logs integrated from the OpenShift Console (Observe > Logs).

[source,bash]
----
$ oc patch consoles.operator.openshift.io cluster --type=merge --patch '{ "spec": { "plugins": ["logging-view-plugin"] } }'
----

== Delete the Elasticsearch Stack

Once the retention period for logs stored in Elasticsearch expires and no more logs are visible in Kibana, remove the old stack to release resources.

=== Step 1: Delete Elasticsearch and Kibana Resources

[source,bash]
----
$ oc -n openshift-logging delete kibana/kibana elasticsearch/elasticsearch
----

===

 Step 2: Delete the PVCs Used by Elasticsearch Instances

[source,bash]
----
$ oc delete -n openshift-logging pvc -l logging-cluster=elasticsearch
----
