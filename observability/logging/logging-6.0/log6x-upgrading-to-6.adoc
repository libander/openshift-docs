:_mod-docs-content-type: ASSEMBLY
include::_attributes/common-attributes.adoc[]
[id="log6x-upgrading-to-6"]
= Upgrading to Logging 6.0
:context: log6x

toc::[]

Logging v6.0 is a significant upgrade from previous releases, achieving several longstanding goals of Cluster Logging:

* Introduction of distinct operators to manage logging components (e.g., collectors, storage, visualization).
* Removal of support for managed log storage and visualization based on Elastic products (i.e., Elasticsearch, Kibana).
* Deprecation of the Fluentd log collector implementation.
* Removal of support for `ClusterLogging.logging.openshift.io` and `ClusterLogForwarder.logging.openshift.io` resources.

[NOTE]
====
The *cluster-logging-operator* does not provide an automated upgrade process.
====

Given the various configurations for log collection, forwarding, and storage, no automated upgrade is provided by the *cluster-logging-operator*. This documentation assists administrators in converting existing `ClusterLogging.logging.openshift.io` and `ClusterLogForwarder.logging.openshift.io` specifications to the new API. Examples of migrated `ClusterLogForwarder.observability.openshift.io` resources for common use cases are included.


== Log Storage

The only managed log storage solution available in this release is a Lokistack, managed by the *loki-operator*. This solution, previously available as the preferred alternative to the managed Elasticsearch offering, remains unchanged in its deployment process.
// Something recently changed in the code re the Lokistack CR relating to the CLF?

[IMPORTANT]
====
To continue using an existing Red Hat managed Elasticsearch deployment provided by the *elasticsearch-operator*, remove the owner references from the `Elasticsearch` resource named `elasticsearch` in the `openshift-logging` namespace before removing the `ClusterLogging` resource named `instance` in the same namespace.
====

== Log Visualization

The OpenShift console UI plugin for log visualization has been moved to the *cluster-observability-operator* from the *cluster-logging-operator*.
// Pending support statement.

[IMPORTANT]
====
To continue using an existing Red Hat managed Kibana deployment provided by the *elasticsearch-operator*, remove the owner references from the `Kibana` resource named `kibana` in the `openshift-logging` namespace before removing the `ClusterLogging` resource named `instance` in the same namespace.
====

== Log Collection and Forwarding
// Can't link to github, need to figure a workaround.

Log collection and forwarding configurations are now specified under the new link:../../reference/operator/api_observability_v1.adoc[API], part of the `observability.openshift.io` API group. The following sections highlight the differences from the old API resources.

[NOTE]
====
Vector is the only supported collector implementation.
====

== Management, Resource Allocation, and Workload Scheduling

Configuration for management state (e.g., Managed, Unmanaged), resource requests and limits, tolerations, and node selection is now part of the new *ClusterLogForwarder* API.

.Previous Configuration
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
spec:
  managementState: "Managed"
  collection:
    resources:
      limits: {}
      requests: {}
    nodeSelector: {}
    tolerations: {}
----

.Current Configuration
[source,yaml]
----
apiVersion: "observability.openshift.io/v1"
kind: ClusterLogForwarder
spec:
  managementState: Managed
  collector:
    resources:
      limits: {}
      requests: {}
    nodeSelector: {}
    tolerations: {}
----

== Input Specifications

The input specification is an optional part of the *ClusterLogForwarder* specification. Administrators can continue to use the predefined values of *application*, *infrastructure*, and *audit* to collect these sources. d.

=== Application Inputs

Namespace and container inclusions and exclusions have been consolidated into a single field.

.5.9 Application Input with Namespace and Container Includes and Excludes
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: ClusterLogForwarder
spec:
  inputs:
   - name: application-logs
     type: application
     application:
       namespaces:
       - foo
       - bar
       includes:
       - namespace: my-important
         container: main
       excludes:
       - container: too-verbose
----

.6.0 Application Input with Namespace and Container Includes and Excludes
[source,yaml]
----
apiVersion: "observability.openshift.io/v1"
kind: ClusterLogForwarder
spec:
  inputs:
   - name: application-logs
     type: application
     application:
       includes:
       - namespace: foo
       - namespace: bar
       - namespace: my-important
         container: main
       excludes:
       - container: too-verbose
----

[NOTE]
====
*application*, *infrastructure*, and *audit* are reserved words and cannot be used as names when defining an input.
====

=== Input Receivers

Changes to input receivers include:

* Explicit configuration of the type at the receiver level.
* Port settings moved to the receiver level.

.5.9 Input Receivers
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: ClusterLogForwarder
spec:
  inputs:
  - name: an-http
    receiver:
      http:
        port: 8443
        format: kubeAPIAudit
  - name: a-syslog
    receiver:
      type: syslog
      syslog:
        port: 9442
----

.6.0 Input Receivers
[source,yaml]
----
apiVersion: "observability.openshift.io/v1"
kind: ClusterLogForwarder
spec:
  inputs:
  - name: an-http
    type: receiver
    receiver:
      type: http
      port: 8443
      http:
        format: kubeAPIAudit
  - name: a-syslog
    type: receiver
    receiver:
      type: syslog
      port: 9442
----

== Output Specifications

High-level changes to output specifications include:

* URL settings moved to each output type specification.
* Tuning parameters moved to each output type specification.
* Separation of TLS configuration from authentication.
* Explicit configuration of keys and secret/configmap for TLS and authentication.

== Secrets and TLS Configuration

Secrets and TLS configurations are now separated into authentication and TLS configuration for each output. They must be explicitly defined in the specification rather than relying on administrators to define secrets with recognized keys. Upgrading TLS and authorization configurations requires administrators to understand previously recognized keys to continue using existing secrets. Examples in the following sections provide details on how to configure *ClusterLogForwarder* secrets to forward to existing Red Hat managed log storage solutions.

== Red Hat Managed Elasticsearch

.v5.9 Forwarding to Red Hat Managed Elasticsearch
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: instance
  namespace: openshift-logging
spec:
  logStore:
    type: elasticsearch
----

.v6.0 Forwarding to Red Hat Managed Elasticsearch
[source,yaml]
----
apiVersion: "observability.openshift.io/v1"
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  outputs:
  - name: default-elasticsearch
    type: elasticsearch
    elasticsearch:
      url: https://elasticsearch:9200
      version: 6
      index: "{.log_type}-write"
    tls:
      ca:
        key: ca-bundle.crt
        secretName: collector
      certificate:
        key: tls.crt
        secretName: collector
      key:
        key: tls.key
        secretName: collector
  pipelines:
  - outputRefs:
    - default-elasticsearch
  - inputRefs:
    - application
    - infrastructure
----

[NOTE]
====
In this example, application logs are written to the `application-write` alias/index instead of `app-write`.
====

== Red Hat Managed LokiStack

.v5.9 Forwarding to Red Hat Managed LokiStack
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: instance
  namespace: openshift-logging
spec:
  logStore:
    type: lokistack
    lokistack:
      name: lokistack-dev
----

.v6.0 Forwarding to Red Hat Managed LokiStack
[source,yaml]
----
apiVersion: "observability.openshift.io/v1"
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  outputs:
  - name: default-lokistack
    type: lokiStack
    lokiStack:
      target:
        name: lokistack-dev
        namespace: openshift-logging
      authentication:
        token:
          from: secret
        secret:
          key: token
          secretName: logcollector-token
    tls:
      ca:
        key: service-ca.crt
        configMapName: openshift-service-ca.crt
  pipelines:
  - outputRefs:
    - default-lokistack
  - inputRefs:
    - application
    - infrastructure
----

== Filters and Pipeline Configuration

Pipeline configurations now define only the routing of input sources to their output destinations, with any required transformations configured separately as filters. All attributes of pipelines from previous releases have been converted to filters in this release. Individual filters are defined in the `filters` specification and referenced by a pipeline.

.5.9 Filters
[source,yaml]
----
apiVersion: "logging.openshift.io/v1"
kind: ClusterLogForwarder
spec:
  pipelines:
   - name: application-logs
     parse: json
     labels:
       foo: bar
     detectMultilineErrors: true
----

.6.0 Filter Configuration
[source,yaml]
----
apiVersion: "observability.openshift.io/v1"
kind: ClusterLogForwarder
spec:
  filters:
  - name: detectexception
    type: detectMultilineException
  - name: parse-json
    type: parse
  - name: labels
    type: openShiftLabels
    openShiftLabels:
      foo: bar
  pipelines:
  - name: application-logs
    filterRefs:
    - detectexception
    - labels
    - parse-json
----

== Validation and Status

Most validations are enforced when a resource is created or updated, providing immediate feedback. This is a departure from previous releases, where validation occurred post-creation and required inspecting the resource status. Some validation still occurs post-creation for cases where it is not possible to validate at creation or update time.

Instances of the `ClusterLogForwarder.observability.openshift.io` must satisfy the following conditions before the operator will deploy the log collector: Authorized, Valid, Ready. An example of these conditions is:

.6.0 Status Conditions
[source,yaml]
----
apiVersion: "observability.openshift.io/v1"
kind: ClusterLogForwarder
status:
  conditions:
  - message: ""
    status: "True"
    type: Ready
  - message: "permitted to collect log types: [application]"
    reason: ClusterRoleExists
    status: "True"
    type: observability.openshift.io/Authorized
  - message: ""
    reason: Validation Success
    status: "True"
    type: observability.openshift.io/Valid
  inputs:
  - message: ""
    status: "True"
    type: observability.openshift.io/Valid-application
  outputs:
  - message: ""
    status: "True"
    type: observability.openshift.io/Valid-rh-loki
  pipelines:
  - message: ""
    status: "True"
    type: observability.openshift.io/Valid-application-logs
----

[NOTE]
====
Conditions that are satisfied and applicable have a "status" value of "True". Conditions with a status other than "True" provide a reason and a message explaining the issue.
====
