:_mod-docs-content-type: ASSEMBLY
include::_attributes/common-attributes.adoc[]
[id="log6x-about"]
= About logging 6.0
:context: logging-6x

toc::[]

The `ClusterLogForwarder` custom resource is the central configuration point for OpenShift Logging 6.0. It defines the desired state of your logging system, including inputs, outputs, and pipelines. The Cluster Logging Operator watches for changes to this resource and automatically applies the necessary configurations to the underlying logging components.

== Service account
This release of Cluster Logging requires administrators to explicitly grant log collection permissions to the service account associated with *ClusterLogForwarder*. This was not required in previous releases for the legacy logging scenario consisting of a *ClusterLogging* and, optionally, a *ClusterLogForwarder.logging.openshift.io* resource.

To use the existing service account (that is, `logcollector`) from a previous release, create the following *ClusterRoleBinding*:

[source,terminal]
----
$ oc adm policy add-cluster-role-to-user collect-application-logs -z openshift-logging:logcollector
$ oc adm policy add-cluster-role-to-user collect-infrastructure-logs -z openshift-logging:logcollector
----

Additionally, create the following *ClusterRoleBinding* if collecting audit logs:

[source,terminal]
----
$ oc adm policy add-cluster-role-to-user collect-audit-logs -z openshift-logging:logcollector
----

== Inputs and Outputs

Inputs specify the sources of logs to be forwarded. OpenShift Logging 6.0 provides built-in input types such as `application`, `infrastructure`, and `audit`, which select logs from different parts of your OpenShift cluster. You can also define custom inputs based on namespaces or pod labels to fine-tune log selection.

Outputs define the destinations where logs are sent. Various output types are supported, including Elasticsearch, Fluentd, Syslog, Kafka, Loki, and CloudWatch. Each output type has its own set of configuration options, allowing you to customize the behavior and authentication settings.

== Pipelines and Filters

Pipelines determine the flow of logs from inputs to outputs. A pipeline consists of one or more input refs, output refs, and optional filter refs. Filters can be used to transform or drop log messages within a pipeline. The order of filters matters, as they are applied sequentially, and earlier filters can prevent log messages from reaching later stages.

== Operator Behavior

The Cluster Logging Operator manages the deployment and configuration of the logging components based on the `ClusterLogForwarder` resource. The `managementState` field controls the operator's behavior:

- When set to `managed` (default), the operator actively manages the logging resources to match the desired state defined in the spec.
- When set to `unmanaged`, the operator does not take any action, allowing you to manually manage the logging components.


== Validation
Logging 6.0 includes extensive validation rules and default values to ensure a smooth and error-free configuration experience. The `ClusterLogForwarder` resource enforces validation checks on required fields, dependencies between fields, and the format of input values. Default values are provided for certain fields, reducing the need for explicit configuration in common scenarios.

include::modules/log6x-oc-explain.adoc[leveloffset=+1]
