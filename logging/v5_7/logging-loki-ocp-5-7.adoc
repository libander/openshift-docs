:_content-type: ASSEMBLY
[id="logging-loki-ocp_{context}"]
= Setting up logging
include::_attributes/common-attributes.adoc[]
:context: logging-loki

toc::[]

An essential function of {product-title} is the collection and aggregation of logs from the environments and application pods it runs.

To achieve this, the {logging-title} uses Vector and Loki. Vector is a high-performance observability data pipeline that allows users to configure log forwarders to direct logs to different locations. Loki is a horizontally scalable, highly available, multi-tenant log aggregation system that indexes metadata about logs with labels, similar to Prometheus labels. The log data is compressed and stored in chunks in object stores. Logging is designed to work with the default configuration, which is optimized for small to medium-sized clusters.

In {logging} documentation, *LokiStack* refers to the {logging} supported combination of Loki, and web proxy with {product-title} authentication integration. LokiStack's proxy uses {product-title} authentication to enforce multi-tenancy. *Loki* refers to the object store as either the individual component or an external store. You can query Loki link:https://grafana.com/docs/loki/latest/logql/[using a query language called LogQL].

include::modules/logging-support-considerations.adoc[leveloffset=+1]

[id="loki-deployment-sizing_{context}"]
== Deployment Sizing

include::snippets/logging-loki-size-snip.adoc[]

include::modules/logging-loki-gui-install.adoc[leveloffset=+1]

include::modules/logging-loki-cli-install.adoc[leveloffset=+1]

=== Troubleshooting installation issues

include::snippets/logging-install-trouble-snip.adoc[]

include::modules/logging-loki-storage.adoc[leveloffset=+1]

== Creating the `LokiStack` CR

1. Click on *Operators* and then *Installed Operators*.

  a. Select the *Loki Operator*.

  b. On the first page under *Provided APIs* and *LokiStack*, select *Create instance*.

  c. Switch to the *YAML view* option.

  d. Replace the YAML present using the template below:
+
--
include::snippets/logging-lokistack-cr-snip.adoc[]
--
  e. Then click *Create*.

== Creating the *ClusterLogging* CR instance

1. Click on *Operators* and then *Installed Operators*.

a. Select the *Red Hat OpenShift Logging* Operator.

b. On the first page, under *Provided APIs* and *Cluster Logging*, select *Create instance*.

c. Replace the YAML present using the template below:
+
--
include::snippets/logging-clusterlogging-cr-snip.adoc[]
--
This creates an instance of `ClusterLogging` within the namespace `openshift-logging`.

d. Click *Create*.

=== Verify the Logging install

Now that Logging has been created, verify the installation.

1. Switch to the *Workloads* â†’ *Pods* page.

2. Select the *openshift-logging* project.

3. Verify that you see the following pods: *cluster logging*, *collectors*, *logging-view-plugin*, and various *lokistack* pods.

4. Shortly after installation, a box in the top right corner displays "Web console update is available" and prompts you to refresh your browser. Refresh the page and verify that you see the logs.


== Observing the logs

1. Select *Observe* -> *Logs* on the left menu.

2. Verify that you see the logs grouped in *application*, *infrastructure*, and *audits* sections.

[NOTE]
====
`audit` logs are not collected by default.
====

You can filter by *Content*, *Namespaces*, *Pods*, and *Containers*.
This can be useful to narrow down searches when looking for something more specific.

You can further specify the logs you are looking for by using the other drop-down menu for *Severity*. This menu breaks the logs into *critical*, *error*, *warning*, *debug*, *info*, *trace*, and *unknown* logging categories.

The final section is the *histogram*. This shows how many log entries match the given query over time and can give you an indication of when events happened more frequently.

=== Accessing audit logs

To have access to *audit logs*, log forwarding must be set up.

1. In the {product-title} web console, click *Operators* -> *OperatorHub*.

2. Select *Red Hat OpenShift Logging*.

3. Select *Provided APIs* then *Cluster Log Forwarder* and click *Create instance*.

4. Replace the YAML displayed with the following template:
+
[source,yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  pipelines:
  - name: all-to-default
    inputRefs:
    - infrastructure
    - application
    - audit
    outputRefs:
    - default
----

5. Next, click *create*.

6. You should now be able to go back to *Observe* -> *Logs* and select *Audit* from the menu.

include::modules/logging-loki-logcli.adoc[leveloffset=+2]
